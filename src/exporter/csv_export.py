"""Utilities for exporting approved review data to CSV and QA reports."""

from __future__ import annotations

import csv
import json
import sqlite3
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Mapping, MutableMapping, Sequence, Tuple

__all__ = ["CsvExporter", "ExportResult"]


@dataclass(slots=True)
class ExportResult:
    """Representation of the artefacts generated by the exporter."""

    csv_path: Path
    qa_path: Path
    stats: Mapping[str, object]


class CsvExporter:
    """Export approved review data as semicolon separated CSV files.

    The exporter inspects the review database for documents marked as
    ``APPROVED`` and composes a consolidated dataset matching the downstream
    electoral schema. In addition to the CSV, a QA report capturing counts and
    basic quality indicators is produced alongside the export so operators can
    track review throughput.
    """

    FIELD_ORDER: Sequence[Tuple[str, str]] = (
        ("dtmnfr", "DTMNFR"),
        ("orgao", "ORGAO"),
        ("sigla", "SIGLA"),
        ("simbolo", "SIMBOLO"),
        ("nome_lista", "NOME_LISTA"),
        ("tipo", "TIPO"),
        ("num_ordem", "NUM_ORDEM"),
        ("nome_candidato", "NOME_CANDIDATO"),
        ("partido_proponente", "PARTIDO_PROPONENTE"),
        ("independente", "INDEPENDENTE"),
    )

    def __init__(self, db_path: Path | str, output_dir: Path | str | None = None) -> None:
        self.db_path = Path(db_path)
        if output_dir is None:
            output_dir = self.db_path.parent / "exports"
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------
    def export(self) -> ExportResult:
        """Generate the CSV export and accompanying QA report."""

        approved_documents = self._fetch_approved_document_ids()
        if not approved_documents:
            raise ValueError("No approved documents available for export.")

        rows, stats = self._collect_rows(approved_documents)
        if not rows:
            raise ValueError("No comparison rows found for the approved documents.")

        timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        base_name = f"approved_candidates_{timestamp}"
        csv_path = self.output_dir / f"{base_name}.csv"
        qa_path = self.output_dir / f"{base_name}_qa.json"

        self._write_csv(csv_path, rows)
        self._write_qa_report(qa_path, stats)

        return ExportResult(csv_path=csv_path, qa_path=qa_path, stats=stats)

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------
    def _fetch_approved_document_ids(self) -> Sequence[int]:
        query = "SELECT id FROM documents WHERE status = 'APPROVED' ORDER BY id"
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(query)
            rows = cursor.fetchall()
        return [row[0] for row in rows]

    def _collect_rows(self, document_ids: Sequence[int]) -> Tuple[List[Mapping[str, object]], Dict[str, object]]:
        placeholders = ",".join("?" for _ in document_ids)
        query = f"""
            SELECT
                c.id,
                c.document_id,
                c.status,
                c.payload,
                d.selected_source,
                d.final_value,
                d.comment,
                d.reviewer,
                d.decided_at
            FROM candidate_comparisons AS c
            LEFT JOIN review_decisions AS d ON d.comparison_id = c.id
            WHERE c.document_id IN ({placeholders})
            ORDER BY c.document_id, c.tipo, c.num_ordem, c.id
        """

        exported_rows: List[Mapping[str, object]] = []
        documents_seen: set[int] = set()
        disputes = 0
        manual_edits = 0
        reviewed_rows = 0

        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(query, list(document_ids))
            for (
                comparison_id,
                document_id,
                status,
                payload,
                selected_source,
                final_value,
                comment,
                reviewer,
                decided_at,
            ) in cursor.fetchall():
                documents_seen.add(document_id)
                if status == "dispute":
                    disputes += 1

                payload_data = self._parse_payload(payload)
                row = self._build_row(
                    document_id=document_id,
                    payload=payload_data,
                    selected_source=selected_source,
                    final_value=final_value,
                )
                exported_rows.append(row)

                if selected_source or final_value or comment or reviewer:
                    reviewed_rows += 1
                if self._is_manual_edit(selected_source, final_value, payload_data):
                    manual_edits += 1

        disagreement_percentage = (disputes / len(exported_rows) * 100) if exported_rows else 0.0
        stats: Dict[str, object] = {
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "documents": len(documents_seen),
            "rows": len(exported_rows),
            "disputes": disputes,
            "disagreement_percentage": round(disagreement_percentage, 2),
            "manual_edits": manual_edits,
            "reviewed_rows": reviewed_rows,
        }
        return exported_rows, stats

    def _parse_payload(self, payload: str | bytes | None) -> Mapping[str, Mapping[str, object]]:
        if not payload:
            return {}
        if isinstance(payload, bytes):
            payload = payload.decode("utf-8")
        try:
            parsed = json.loads(payload)
        except json.JSONDecodeError:
            return {}
        operator_a = parsed.get("operator_a") or {}
        operator_b = parsed.get("operator_b") or {}
        return {"operator_a": operator_a, "operator_b": operator_b}

    def _build_row(
        self,
        *,
        document_id: int,
        payload: Mapping[str, Mapping[str, object]],
        selected_source: str | None,
        final_value: object | None,
    ) -> Mapping[str, object]:
        operator_a = payload.get("operator_a") or {}
        operator_b = payload.get("operator_b") or {}

        if selected_source == "operator_b":
            primary, secondary = operator_b, operator_a
        else:
            primary, secondary = operator_a, operator_b

        merged: MutableMapping[str, object] = {}
        for key, _ in self.FIELD_ORDER:
            if key == "nome_candidato":
                # Handled after the loop to apply manual overrides.
                continue
            value = self._choose_value(primary.get(key), secondary.get(key))
            merged[key] = value

        final_name = self._choose_value(final_value, primary.get("nome_candidato"), operator_b.get("nome_candidato"))
        merged["nome_candidato"] = final_name
        merged["document_id"] = document_id
        merged["tipo"] = self._coerce_int(merged.get("tipo"))
        merged["num_ordem"] = self._coerce_int(merged.get("num_ordem"))
        merged["independente"] = 1 if self._coerce_int(merged.get("independente")) else 0
        return merged

    def _is_manual_edit(
        self,
        selected_source: str | None,
        final_value: object | None,
        payload: Mapping[str, Mapping[str, object]],
    ) -> bool:
        if selected_source == "manual":
            return True
        if not final_value:
            return False
        value = str(final_value)
        for source in (payload.get("operator_a") or {}, payload.get("operator_b") or {}):
            candidate = source.get("nome_candidato")
            if candidate is not None and str(candidate) == value:
                return False
        return True

    def _choose_value(self, *values: object | None) -> object | None:
        for value in values:
            if value is None:
                continue
            if isinstance(value, str) and value.strip() == "":
                continue
            return value
        return None

    def _coerce_int(self, value: object | None) -> int | None:
        if value is None or value == "":
            return None
        try:
            return int(value)
        except (TypeError, ValueError):
            return None

    def _write_csv(self, csv_path: Path, rows: Sequence[Mapping[str, object]]) -> None:
        ordered_rows = sorted(
            rows,
            key=lambda item: (
                item.get("document_id") or 0,
                item.get("tipo") or 0,
                item.get("num_ordem") or 0,
            ),
        )

        with csv_path.open("w", encoding="utf-8", newline="") as handle:
            writer = csv.writer(handle, delimiter=";", quoting=csv.QUOTE_MINIMAL)
            writer.writerow([header for _, header in self.FIELD_ORDER])
            for row in ordered_rows:
                writer.writerow([self._format_cell(row.get(key)) for key, _ in self.FIELD_ORDER])

    def _format_cell(self, value: object | None) -> str:
        if value is None:
            return ""
        if isinstance(value, bool):
            return "1" if value else "0"
        if isinstance(value, (int, float)):
            if isinstance(value, bool):  # pragma: no cover - already handled above
                return "1" if value else "0"
            return str(int(value)) if isinstance(value, float) and value.is_integer() else str(value)
        return str(value)

    def _write_qa_report(self, qa_path: Path, stats: Mapping[str, object]) -> None:
        with qa_path.open("w", encoding="utf-8") as handle:
            json.dump(stats, handle, indent=2, ensure_ascii=False)
            handle.write("\n")
